{"componentChunkName":"component---src-templates-presentations-index-tsx","path":"/presentations/","result":{"pageContext":{"presentations":[{"node":{"id":"65b8b32916500e7a28699d61","slug":"test-ppt","url":"https://xprilion.com/test-ppt","title":"Presentation::Test ppt","subtitle":null,"brief":"Overview\nDuration: 1\nHey there!\nThis codelab will walffffffk you through the process of creating a simple \"Hello World\" application using Python Flask and deploying it to Google Cloud Run.\nRequirements\nDuration: 2\nIn order to follow this codelab, you...","coverImage":null,"content":{"html":"<h2 id=\"heading-overview\">Overview</h2>\n<p>Duration: 1</p>\n<p>Hey there!</p>\n<p>This codelab will walffffffk you through the process of creating a simple \"Hello World\" application using Python Flask and deploying it to Google Cloud Run.</p>\n<h2 id=\"heading-requirements\">Requirements</h2>\n<p>Duration: 2</p>\n<p>In order to follow this codelab, you'll need the following:</p>\n<ol>\n<li><p>A Google Cloud Platform account.</p>\n</li>\n<li><p>Google Cloud CLI installed and initialized.</p>\n</li>\n<li><p>Python installed locally.</p>\n</li>\n</ol>\n<h2 id=\"heading-setting-up-your-google-cloud-account\">Setting Up Your Google Cloud Account</h2>\n<p>Duration: 10</p>\n<ol>\n<li><p>Head over to <a target=\"_blank\" href=\"https://console.cloud.google.com/\">Google Cloud Platform</a> and create an account.</p>\n</li>\n<li><p>Enable billing</p>\n</li>\n<li><p>Create a new project, let's name it <code>project-x</code>.</p>\n</li>\n</ol>\n<h2 id=\"heading-install-google-cloud-cli\">Install Google Cloud CLI</h2>\n<p>Duration: 5</p>\n<p>Follow the official guide to install the Google Cloud CLI: <a target=\"_blank\" href=\"https://cloud.google.com/sdk/docs/install\">Installing Google Cloud SDK</a>.</p>\n<h2 id=\"heading-create-and-run-the-flask-application\">Create and Run the Flask Application</h2>\n<p>Duration: 15</p>\n<ol>\n<li><p>Set up a new directory for your project:</p>\n<pre><code class=\"lang-bash\"> mkdir hello-world-cloud-run\n <span class=\"hljs-built_in\">cd</span> hello-world-cloud-run\n</code></pre>\n</li>\n<li><p>Create a Python virtual environment and activate it:</p>\n<pre><code class=\"lang-bash\"> python3 -m venv .venv\n <span class=\"hljs-built_in\">source</span> .venv/bin/activate\n</code></pre>\n</li>\n<li><p>Install Flask:</p>\n<pre><code class=\"lang-bash\"> pip install Flask\n</code></pre>\n</li>\n<li><p>Create a file named <a target=\"_blank\" href=\"http://main.py\"><code>main.py</code></a> with the following content:</p>\n<pre><code class=\"lang-python\"> <span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask\n <span class=\"hljs-keyword\">import</span> os\n\n app = Flask(__name__)\n\n<span class=\"hljs-meta\"> @app.route('/')</span>\n <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">hello_world</span>():</span>\n     <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'Hello, World!'</span>\n\n <span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n     app.run(debug=<span class=\"hljs-literal\">True</span>, host=<span class=\"hljs-string\">\"0.0.0.0\"</span>, port=int(os.environ.get(<span class=\"hljs-string\">\"PORT\"</span>, <span class=\"hljs-number\">8080</span>)))\n</code></pre>\n</li>\n</ol>\n<h2 id=\"heading-running-the-app-locally\">Running the App Locally</h2>\n<p>Duration: 2</p>\n<ol>\n<li><p>Run your application locally:</p>\n<pre><code class=\"lang-bash\"> python main.py\n</code></pre>\n</li>\n<li><p>Open your web browser and go to <a target=\"_blank\" href=\"http://localhost:8080\"><code>http://localhost:8080</code></a>. You should see the \"Hello, World!\" message.</p>\n</li>\n</ol>\n<h2 id=\"heading-deploy-to-google-cloud-run\">Deploy to Google Cloud Run</h2>\n<p>Duration: 5</p>\n<ol>\n<li><p>Generate the requirements.txt file</p>\n<pre><code class=\"lang-bash\"> pip list --format=freeze &gt; requirements.txt\n</code></pre>\n</li>\n<li><p>Deploy your application to Google Cloud Run:</p>\n<pre><code class=\"lang-bash\"> gcloud run deploy\n</code></pre>\n</li>\n<li><p>Wait for the deployment to complete. You will receive a URL where your application is live.</p>\n</li>\n</ol>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>Duration: 1</p>\n<p>Congratulations! You've just built and deployed a simple application on Google Cloud Run using Python and Flask!</p>\n<h2 id=\"heading-whats-next\">What's Next?</h2>\n<p>Duration: 1</p>\n<ul>\n<li><p>Experiment with adding more routes and functionalities to your Flask application.</p>\n</li>\n<li><p>Learn more about managing and monitoring your applications on Google Cloud Run.</p>\n</li>\n<li><p>Explore other Google Cloud services that can enhance your application.</p>\n</li>\n</ul>\n"},"publishedAt":"2024-01-30T08:28:25.768Z","seo":{"title":null,"description":null},"tags":[{"slug":"ppt"}]}},{"node":{"id":"6571da74cabbbca2f1bf829e","slug":"high-availability-ml-deployments","url":"https://xprilion.com/high-availability-ml-deployments","title":"High Availability ML Deployments","subtitle":null,"brief":"The average cost of IT downtime is $5,600 per minute.\n~ Gartner\n\nDowntimes can be costly. During downtimes, a company may face loss of business, loss of customer trust, loss of reputation in the technical and business community, or even all of these ...","coverImage":{"url":"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960031697/d3227ce0-d061-43db-a517-a27f364666b8.png"},"content":{"html":"<blockquote>\n<p>The average cost of IT downtime is $5,600 per minute.</p>\n<p>~ Gartner</p>\n</blockquote>\n<p>Downtimes can be costly. During downtimes, a company may face loss of business, loss of customer trust, loss of reputation in the technical and business community, or even all of these together. Downtimes are not fun, and until it happens to us, we all tend to think it cannot happen to us.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960112859/5ef3fcf5-6c79-4b1b-b2d5-a62dab91504c.png\" alt class=\"image--center mx-auto\" /></p>\n<p>What makes the challenge more difficult is the fact that the world is rapidly incorporating more and more Machine learning on the web, and this has led to complexities that did not exist with non-ML software solutions.</p>\n<p>In this blog, we'll be exploring how to design a machine learning based solution that is highly reliable and does not suffer much when downtimes occur.</p>\n<p>In this 2 part article, we’ll try to find answers to the following questions:</p>\n<ul>\n<li><p>How quickly can your system bounce back from disasters?</p>\n</li>\n<li><p>Are your ML deployments resilient?</p>\n</li>\n<li><p>When can you call your system architecture “high availability”?</p>\n</li>\n</ul>\n<h2 id=\"heading-part-1-undestanding-hadr-systems\">Part 1 - Undestanding HADR systems</h2>\n<p>Let us begin by understanding a few basics of High Availability Disaster Recovery (HADR) systems. We'll cover a few key terms and then some common system topologies.</p>\n<h3 id=\"heading-key-terms-related-to-hadr-systems\">Key terms related to HADR systems</h3>\n<p>Key terms that you should know about HADR systems -</p>\n<h4 id=\"heading-high-availability\">High Availability</h4>\n<p>High availability (HA) describes the ability of an application to withstand all planned and unplanned outages (a planned outage could be performing a system upgrade) and to provide continuous processing for business-critical applications.</p>\n<h4 id=\"heading-disaster-recovery\">Disaster Recovery</h4>\n<p>Disaster recovery (DR) involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.</p>\n<h4 id=\"heading-unplanned-downtime\">Unplanned downtime</h4>\n<p>Downtime caused by factors which were not introduced on purpose is called unplanned downtime. This can be majorly due to:</p>\n<ul>\n<li><p>Human Error</p>\n</li>\n<li><p>Software Problems</p>\n</li>\n<li><p>Hardware Failure</p>\n</li>\n<li><p>Environmental Issues</p>\n</li>\n</ul>\n<p><img src=\"https://media.tenor.com/VYujs2dkFTUAAAAC/gopi-bahu.gif\" alt=\"Unplanned downtime meme\" /></p>\n<h4 id=\"heading-planned-downtime\">Planned downtime</h4>\n<p>The opposite of unplanned downtime.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960127488/0c6eef40-e655-4d53-b6f5-f231a61ca373.png\" alt class=\"image--center mx-auto\" /></p>\n<p>Downtimes introduced on purpose, mostly are:</p>\n<ul>\n<li><p>System upgrades</p>\n</li>\n<li><p>System repairs</p>\n</li>\n<li><p>Restricted access due to business reasons</p>\n</li>\n</ul>\n<h4 id=\"heading-chaos-engineering\">Chaos Engineering</h4>\n<p>Chaos engineering is a method of testing distributed software that deliberately introduces failure and faulty scenarios to verify its resilience in the face of random disruptions. These disruptions can cause applications to respond in unpredictable ways and can break under pressure.</p>\n<h4 id=\"heading-resilience\">Resilience</h4>\n<p>The ability of a solution to absorb the impact of a problem in one or more parts of a system, while continuing to provide an acceptable service level to the business customers.</p>\n<h3 id=\"heading-key-metrics-for-analyzing-your-system-design\">Key metrics for analyzing your system design</h3>\n<p>The key metrics used to analyze system designs are -</p>\n<ul>\n<li><p>Production capacity in and out of region</p>\n</li>\n<li><p>Platform availability</p>\n</li>\n<li><p>Availability during planned outages</p>\n</li>\n<li><p>Failure Impact</p>\n</li>\n<li><p>Disaster recovery time</p>\n</li>\n<li><p>Incident response time</p>\n</li>\n</ul>\n<p>Next, let's look at some HADR system topologies, before we compare their metrics.</p>\n<h3 id=\"heading-a-30000ft-view-of-high-availability-system-design\">A 30,000ft view of high availability system design</h3>\n<p>HADR systems can be designed with several topologies ranging from simple ones - where you put all your eggs in a single basket - or complex ones - where you devise a fail-safe array of servers. Let us study a couple of them to understand how such topologies look like -</p>\n<p>Consider the following 2-Active topology -</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960139543/0172d1c1-0563-4fa8-9fec-69ddbe54ea48.png\" alt class=\"image--center mx-auto\" /></p>\n<p>This topology shows that we provision 3 servers such that during normal operations, 2 servers load balance the traffic coming to the application while a third server stays on standby. This server gets activated in the event of failure of any or all of the active servers.</p>\n<p>An alternative to a 2-Active system topology is a 3-Active topology -</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960155075/11f765cb-afec-4340-bd52-7cc5038f7615.png\" alt class=\"image--center mx-auto\" /></p>\n<p>In this system topology, we provision all three servers as active servers and in event of failure of any server, the other servers load balance the traffic, while the failed servers are brought back up.</p>\n<p>An obvious question here - which of these is better?</p>\n<p>Consider the following chart of metrics comparison for the above two systems against a single Active system -</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960165457/4a97d05e-a089-49de-9bbb-5d5baac74de1.png\" alt class=\"image--center mx-auto\" /></p>\n<p>From the above, it can be said that while 3-active systems gives highest availability and lowest failure impacts, if your application is likely to expect surges, a 2-active system might give you better resilience.</p>\n<p>We shall wrap our discussion about HADR system topologies here. Next, we'll talk about challenges posed by ML in HADR systems and see a demo of these topologies in action!</p>\n<h2 id=\"heading-part-2-hadr-system-challenges-by-ml-deployments-and-load-testing-ml-hadr-system\">Part 2 - HADR system challenges by ML deployments and load testing ML-HADR system</h2>\n<p>Machine Learning heavy deployments bring their own set of challenges to any HADR system. ML models can be deployed in several ways, due to which it becomes important for architects designing HADR systems to choose the right deployment strategies for best results.</p>\n<h3 id=\"heading-challenges-posed-to-ml-pipelines-for-high-availability\">Challenges posed to ML pipelines for high availability</h3>\n<p>Some of the challenges faced with ML deployments for HADR are -</p>\n<h4 id=\"heading-what-is-a-good-ml-deployment\">What is a good ML deployment?</h4>\n<p>The definition of a good ML deployment changes with who is answering this question. Fir examples -</p>\n<p>Business owners - performs fast inference Researchers - highest accuracy Developers - gets built quickly Q/A engineers - never fails Investors - sounds cool, brings in the $$</p>\n<h4 id=\"heading-volume-of-data-processed\">Volume of data processed</h4>\n<p>Volume of data can be a major challenge to most ML systems. Too much data and you may be running late at your training and too less of it, your inference suffers.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960251922/a7daf4f0-b232-424a-bff0-e65e5f260f04.png\" alt class=\"image--center mx-auto\" /></p>\n<h4 id=\"heading-quality-of-data\">Quality of data</h4>\n<p>Data quality refers to how informative and complete a given chunk of data is. The lower the data quality, the tougher it is to derive insights from it.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960180925/68483f29-961f-4c7a-92d1-12ef172fcbf0.png\" alt class=\"image--center mx-auto\" /></p>\n<h4 id=\"heading-model-decay\">Model decay</h4>\n<p>The phenomenon in Machine Learning that leads to predictions made by a model become less accurate over time. Primary reasons for model decay are:</p>\n<ul>\n<li><p>Data drift</p>\n</li>\n<li><p>Concept drift</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960192366/1a966a6e-e6a5-4a72-9cb3-2f14742d0360.png\" alt class=\"image--center mx-auto\" /></p>\n<h4 id=\"heading-speed-of-inference-against-various-inputs\">Speed of inference against various inputs</h4>\n<p>Speed of inference can change with changing input. If your model performs inference under 1s for most images ranging appx 10MB, what does it do when someone uploads an image of 1GB? Does your system reject the image or does it take down the building?</p>\n<h3 id=\"heading-load-testing-ml-hadr-systems\">Load testing ML-HADR systems</h3>\n<p>Finally, let us load-test a few topologies which server ML based content. To do so, we shall be using the Locus tool along with a self-engineered set of scripts that work as nodes and load balancer.</p>\n<p>I have published the code for this setup here - <a target=\"_blank\" href=\"https://github.com/xprilion/dummy-topology-loadtest\">https://github.com/xprilion/dummy-topology-loadtest</a></p>\n<p>The contents of this system are -</p>\n<ol>\n<li><p><a target=\"_blank\" href=\"http://router.py\"><code>router.py</code></a> : this file will act as a dummy load-balancer.</p>\n</li>\n<li><p><code>predictors/predict**X**.py</code> - these files are numbered, replacing X, and will be active as node servers.</p>\n</li>\n<li><p><code>topology/**topology_name**.json</code> - these json files contain information regarding the topologies available. We will be updating the data inside these files while load testing the topology they represent.</p>\n</li>\n</ol>\n<p>To setup the load test run, first ensure that in the files inside the <code>topology</code> directory, all the topology files are in their initial states, as shown below -</p>\n<h4 id=\"heading-single-server-system\">Single server system</h4>\n<p>In this system, there is a single server handling all resources.</p>\n<pre><code class=\"lang-plaintext\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    }\n}\n</code></pre>\n<h4 id=\"heading-2-active-system\">2 Active system</h4>\n<p>In this system, initially, there are 2 servers responding to requests. In event of failure of any one or both servers, a third system steps in as replacement while the other two are fixed.</p>\n<pre><code class=\"lang-plaintext\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    },\n    \"predict2\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9697\"\n    },\n    \"predict3\": {\n        \"status\": false,\n        \"load\": 0,\n        \"port\": \"9698\"\n    }\n}\n</code></pre>\n<p>Notice that the <code>status</code> of <code>predict3</code> server is set to <code>false</code>.</p>\n<h4 id=\"heading-3-active-system\">3 Active system</h4>\n<p>In a 3-active system, there are 3 servers available to handle requests.</p>\n<pre><code class=\"lang-plaintext\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    },\n    \"predict2\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9697\"\n    },\n    \"predict3\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9698\"\n    }\n}\n</code></pre>\n<p>Then, ensure that in <a target=\"_blank\" href=\"http://router.py\"><code>router.py</code></a>, the <code>topology</code> variable is set to <code>0</code>. This will correspond to the single server system.</p>\n<p>Next, we fire up the Locus UI by running the <code>locust</code> command inside the <code>locust</code> directory.</p>\n<p>Specify the number of users to spawn and the spawn rate. Provide a suitable host. Locust will inform the server under stress that the requests are coming from the specified host.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960270987/3aeec339-28bc-461c-82a4-952f95fd7c4f.png\" alt class=\"image--center mx-auto\" /></p>\n<p>Click on <strong>Start Swarming</strong> to start throwing requests at the server based on the script specified in the <code>locust/</code><a target=\"_blank\" href=\"http://locustfile.py\"><code>locustfile.py</code></a>.</p>\n<p>Observe the charts that show how the system is responding to the increase in the load. After some time, the first server failures start appearing. We'll keep a note of when the first error appears.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1701960281544/39cba6e0-15c5-4b83-ad3d-7f340dace496.png\" alt class=\"image--center mx-auto\" /></p>\n<p>Now, change the <code>topology</code> variable in <a target=\"_blank\" href=\"http://router.py\"><code>router.py</code></a> to <code>1</code> and run Locust. In the next step, change the <code>topology</code> variable to <code>2</code> and run Locust again.</p>\n<p>Let's plot a chart of when the first failures happen in case of each system -</p>\n<div class=\"hn-table\">\n<table>\n<thead>\n<tr>\n<td>Topology</td><td>RPS at failure</td></tr>\n</thead>\n<tbody>\n<tr>\n<td>Single</td><td>5.2</td></tr>\n<tr>\n<td>2-Active</td><td>8.6</td></tr>\n<tr>\n<td>3-Active</td><td>7.4</td></tr>\n</tbody>\n</table>\n</div><p>As expected, the 2-Active system has the peak capacity in our use-case. However, here's an interesting observation -</p>\n<p>Let us compare the values of the predict servers on 2-Active and 3-Active systems after the load test -</p>\n<div class=\"hn-table\">\n<table>\n<thead>\n<tr>\n<td>Server</td><td>2-Active</td><td>3-Active</td></tr>\n</thead>\n<tbody>\n<tr>\n<td>Predict1</td><td>10</td><td>5</td></tr>\n<tr>\n<td>Predict2</td><td>10</td><td>7</td></tr>\n<tr>\n<td>Predict3</td><td>9</td><td>8</td></tr>\n</tbody>\n</table>\n</div><p>As we see, the 2-Active system is completely saturated while the 3-Active system is slightly above half its capacity.</p>\n<p>Thus, even though the 2-Active system fails after the 3-Active system has shown its first error, the 3-Active system will saturate later and continue to serve requests for a longer duration.</p>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>Depending on the HADR system metric you may want to optimize for, you can choose the topology that works best for your use case. You can choose to have multiple replicas of the same network topology or create your own configuration. The scripts provided for load testing can be extended to more topologies. Have fun testing your HADR system designs with it!</p>\n"},"publishedAt":"2022-10-09T06:30:00.000Z","seo":{"title":"091020221708","description":null},"tags":[{"slug":"blog"},{"slug":"ppt"}]}}]}},"staticQueryHashes":[],"slicesMap":{}}