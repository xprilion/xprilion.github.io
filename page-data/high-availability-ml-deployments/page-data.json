{"componentChunkName":"component---src-templates-blog-post-js","path":"/high-availability-ml-deployments/","result":{"data":{"site":{"siteMetadata":{"title":"xprilion's blog","author":"Anubhav Singh","siteUrl":"https://xprilion.com"}},"markdownRemark":{"id":"06be41c4-745e-528f-86c2-a90b82d4abd8","excerpt":"The average cost of IT downtime is $5,600 per minute.  ~ Gartner Downtimes can be costly. During downtimes, a company may face loss of business, loss of…","html":"<p><img src=\"/images/covers/high-availability-ml-deployments.png\"></p>\n<blockquote>\n<p>The average cost of IT downtime is $5,600 per minute. </p>\n<p>~ Gartner</p>\n</blockquote>\n<p>Downtimes can be costly. During downtimes, a company may face loss of business, loss of customer trust, loss of reputation in the technical and business community, or even all of these together. Downtimes are not fun, and until it happens to us, we all tend to think it cannot happen to us.</p>\n<p><img src=\"/images/2022/October/haml-1.png\" alt=\"Downtime meme\"></p>\n<p>What makes the challenge more difficult is the fact that the world is rapidly incorporating more and more Machine learning on the web, and this has led to complexities that did not exist with non-ML software solutions.</p>\n<p>In this blog, we’ll be exploring how to design a machine learning based solution that is highly reliable and does not suffer much when downtimes occur.</p>\n<p>In this 2 part article, we’ll try to find answers to the following questions:</p>\n<ul>\n<li>How quickly can your system bounce back from disasters?</li>\n<li>Are your ML deployments resilient?</li>\n<li>When can you call your system architecture “high availability”?</li>\n</ul>\n<h2>Part 1 - Undestanding HADR systems</h2>\n<p>Let us begin by understanding a few basics of High Availability Disaster Recovery (HADR) systems. We’ll cover a few key terms and then some common system topologies.</p>\n<h3>Key terms related to HADR systems</h3>\n<p>Key terms that you should know about HADR systems -</p>\n<h4>High Availability</h4>\n<p>High availability (HA) describes the ability of an application to withstand all planned and unplanned outages (a planned outage could be performing a system upgrade) and to provide continuous processing for business-critical applications.</p>\n<h4>Disaster Recovery</h4>\n<p>Disaster recovery (DR) involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system’s essential data in a secure location, and for recovering that data to restore normalcy of operation.</p>\n<h4>Unplanned downtime</h4>\n<p>Downtime caused by factors which were not introduced on purpose is called unplanned downtime. This can be majorly due to:</p>\n<ul>\n<li>Human Error</li>\n<li>Software Problems</li>\n<li>Hardware Failure</li>\n<li>Environmental Issues</li>\n</ul>\n<p><img src=\"https://media.tenor.com/VYujs2dkFTUAAAAC/gopi-bahu.gif\" alt=\"Unplanned downtime meme\"></p>\n<h4>Planned downtime</h4>\n<p>The opposite of unplanned downtime.</p>\n<p><img src=\"/images/2022/October/haml-2.png\" alt=\"Planned downtime meme\"></p>\n<p>Downtimes introduced on purpose, mostly are:</p>\n<ul>\n<li>System upgrades</li>\n<li>System repairs</li>\n<li>Restricted access due to business reasons</li>\n</ul>\n<h4>Chaos Engineering</h4>\n<p>Chaos engineering is a method of testing distributed software that deliberately introduces failure and faulty scenarios to verify its resilience in the face of random disruptions. These disruptions can cause applications to respond in unpredictable ways and can break under pressure.</p>\n<h4>Resilience</h4>\n<p>The ability of a solution to absorb the impact of a problem in one or more parts of a system, while continuing to provide an acceptable service level to the business customers.</p>\n<h3>Key metrics for analyzing your system design</h3>\n<p>The key metrics used to analyze system designs are - </p>\n<ul>\n<li>Production capacity in and out of region</li>\n<li>Platform availability</li>\n<li>Availability during planned outages</li>\n<li>Failure Impact</li>\n<li>Disaster recovery time</li>\n<li>Incident response time</li>\n</ul>\n<p>Next, let’s look at some HADR system topologies, before we compare their metrics.</p>\n<h3>A 30,000ft view of high availability system design</h3>\n<p>HADR systems can be designed with several topologies ranging from simple ones - where you put all your eggs in a single basket - or complex ones - where you devise a fail-safe array of servers. Let us study a couple of them to understand how such topologies look like - </p>\n<p>Consider the following 2-Active topology -</p>\n<p><img src=\"/images/2022/October/haml-3.png\" alt=\"2 Active HADR system topology\"></p>\n<p>This topology shows that we provision 3 servers such that during normal operations, 2 servers load balance the traffic coming to the application while a third server stays on standby. This server gets activated in the event of failure of any or all of the active servers.</p>\n<p>An alternative to a 2-Active system topology is a 3-Active topology -</p>\n<p><img src=\"/images/2022/October/haml-4.png\" alt=\"3 Active HADR system topology\"></p>\n<p>In this system topology, we provision all three servers as active servers and in event of failure of any server, the other servers load balance the traffic, while the failed servers are brought back up.</p>\n<p>An obvious question here - which of these is better?</p>\n<p>Consider the following chart of metrics comparison for the above two systems against a single Active system -</p>\n<p><img src=\"/images/2022/October/haml-5.png\" alt=\"Comparsion chart - single active, 2 active and 3 active system topologies\"></p>\n<p>From the above, it can be said that while 3-active systems gives highest availability and lowest failure impacts, if your application is likely to expect surges, a 2-active system might give you better resilience.</p>\n<p>We shall wrap our discussion about HADR system topologies here. Next, we’ll talk about challenges posed by ML in HADR systems and see a demo of these topologies in action!</p>\n<h2>Part 2 - HADR system challenges by ML deployments and load testing ML-HADR system</h2>\n<p>Machine Learning heavy deployments bring their own set of challenges to any HADR system. ML models can be deployed in several ways, due to which it becomes important for architects designing HADR systems to choose the right deployment strategies for best results.</p>\n<h3>Challenges posed to ML pipelines for high availability</h3>\n<p>Some of the challenges faced with ML deployments for HADR are - </p>\n<h4>What is a good ML deployment?</h4>\n<p>The definition of a good ML deployment changes with who is answering this question. Fir examples -</p>\n<p>Business owners - performs fast inference\nResearchers - highest accuracy\nDevelopers - gets built quickly\nQ/A engineers - never fails\nInvestors - sounds cool, brings in the $$</p>\n<h4>Volume of data processed</h4>\n<p>Volume of data can be a major challenge to most ML systems. Too much data and you may be running late at your training and too less of it, your inference suffers.</p>\n<p><img src=\"/images/2022/October/haml-8.png\" alt=\"Volume of data processed\"></p>\n<h4>Quality of data</h4>\n<p>Data quality refers to how informative and complete a given chunk of data is. The lower the data quality, the tougher it is to derive insights from it. </p>\n<p><img src=\"/images/2022/October/haml-6.png\" alt=\"Volume of data processed\"></p>\n<h4>Model decay</h4>\n<p>The phenomenon in Machine Learning  that leads to predictions made by a model become less accurate over time. Primary reasons for model decay are:</p>\n<ul>\n<li>Data drift</li>\n<li>Concept drift</li>\n</ul>\n<h4>Speed of inference against various inputs</h4>\n<p>Speed of inference can change with changing input. If your model performs inference under 1s for most images ranging appx 10MB, what does it do when someone uploads an image of 1GB? Does your system reject the image or does it take down the building?</p>\n<h3>Load testing ML-HADR systems</h3>\n<p>Finally, let us load-test a few topologies which server ML based content. To do so, we shall be using the Locus tool along with a self-engineered set of scripts that work as nodes and load balancer.</p>\n<p>I have published the code for this setup here - <a href=\"https://github.com/xprilion/dummy-topology-loadtest\">https://github.com/xprilion/dummy-topology-loadtest</a></p>\n<p>The contents of this system are - </p>\n<ol>\n<li><code class=\"language-text\">router.py</code> : this file will act as a dummy load-balancer.</li>\n<li><code class=\"language-text\">predictors/predict**X**.py</code> - these files are numbered, replacing X, and will be active as node servers.</li>\n<li><code class=\"language-text\">topology/**topology_name**.json</code> - these json files contain information regarding the topologies available. We will be updating the data inside these files while load testing the topology they represent.</li>\n</ol>\n<p>To setup the load test run, first ensure that in the files inside the <code class=\"language-text\">topology</code> directory, all the topology files are in their initial states, as shown below - </p>\n<h4>Single server system</h4>\n<p>In this system, there is a single server handling all resources.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    }\n}</code></pre></div>\n<h4>2 Active system</h4>\n<p>In this system, initially, there are 2 servers responding to requests. In event of failure of any one or both servers, a third system steps in as replacement while the other two are fixed.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    },\n    \"predict2\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9697\"\n    },\n    \"predict3\": {\n        \"status\": false,\n        \"load\": 0,\n        \"port\": \"9698\"\n    }\n}</code></pre></div>\n<p>Notice that the <code class=\"language-text\">status</code> of <code class=\"language-text\">predict3</code> server is set to <code class=\"language-text\">false</code>.</p>\n<h4>3 Active system</h4>\n<p>In a 3-active system, there are 3 servers available to handle requests.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n    \"predict1\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9696\"\n    },\n    \"predict2\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9697\"\n    },\n    \"predict3\": {\n        \"status\": true,\n        \"load\": 0,\n        \"port\": \"9698\"\n    }\n}</code></pre></div>\n<p>Then, ensure that in <code class=\"language-text\">router.py</code>, the <code class=\"language-text\">topology</code> variable is set to <code class=\"language-text\">0</code>. This will correspond to the single server system.</p>\n<p>Next, we fire up the Locus UI by running the <code class=\"language-text\">locust</code> command inside the <code class=\"language-text\">locust</code> directory. </p>\n<p>Specify the number of users to spawn and the spawn rate. Provide a suitable host. Locust will inform the server under stress that the requests are coming from the specified host.</p>\n<p><img src=\"/images/2022/October/haml-9.png\" alt=\"Locust setup\"></p>\n<p>Click on <strong>Start Swarming</strong> to start throwing requests at the server based on the script specified in the <code class=\"language-text\">locust/locustfile.py</code>. </p>\n<p>Observe the charts that show how the system is responding to the increase in the load. After some time, the first server failures start appearing. We’ll keep a note of when the first error appears.</p>\n<p><img src=\"/images/2022/October/haml-10.png\" alt=\"Single server system failure\"></p>\n<p>Now, change the <code class=\"language-text\">topology</code> variable in <code class=\"language-text\">router.py</code> to <code class=\"language-text\">1</code> and run Locust. In the next step, change the <code class=\"language-text\">topology</code> variable to <code class=\"language-text\">2</code> and run Locust again.</p>\n<p>Let’s plot a chart of when the first failures happen in case of each system -</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Topology</th>\n<th align=\"center\">RPS at failure</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Single</td>\n<td align=\"center\">5.2</td>\n</tr>\n<tr>\n<td align=\"center\">2-Active</td>\n<td align=\"center\">8.6</td>\n</tr>\n<tr>\n<td align=\"center\">3-Active</td>\n<td align=\"center\">7.4</td>\n</tr>\n</tbody>\n</table>\n<p>As expected, the 2-Active system has the peak capacity in our use-case. However, here’s an interesting observation - </p>\n<p>Let us compare the values of the predict servers on 2-Active and 3-Active systems after the load test - </p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Server</th>\n<th align=\"center\">2-Active</th>\n<th align=\"center\">3-Active</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Predict1</td>\n<td align=\"center\">10</td>\n<td align=\"center\">5</td>\n</tr>\n<tr>\n<td align=\"center\">Predict2</td>\n<td align=\"center\">10</td>\n<td align=\"center\">7</td>\n</tr>\n<tr>\n<td align=\"center\">Predict3</td>\n<td align=\"center\">9</td>\n<td align=\"center\">8</td>\n</tr>\n</tbody>\n</table>\n<p>As we see, the 2-Active system is completely saturated while the 3-Active system is slightly above half its capacity. </p>\n<p>Thus, even though the 2-Active system fails after the 3-Active system has shown its first error, the 3-Active system will saturate later and continue to serve requests for a longer duration.</p>\n<h2>Conclusion</h2>\n<p>Depending on the HADR system metric you may want to optimize for, you can choose the topology that works best for your use case. You can choose to have multiple replicas of the same network topology or create your own configuration. The scripts provided for load testing can be extended to more topologies. Have fun testing your HADR system designs with it!</p>","frontmatter":{"title":"High Availability ML Deployments","date":"October 09, 2022","comments":true,"nid":"091020221708"}}},"pageContext":{"slug":"/high-availability-ml-deployments/","previous":{"fields":{"slug":"/divide-vs-unite/"},"frontmatter":{"title":"Dividing is Easy, Unite if you can"}},"next":{"fields":{"slug":"/python-websockets-ssl-with-lets-encrypt/"},"frontmatter":{"title":"Python Websockets SSL with Let's Encrypt"}}}},"staticQueryHashes":["1296475691","3128451518"]}